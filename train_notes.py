from training_utils import *


def get_sequences_notes(notes, sequence_length=70, data_multiplier=None, verbose=True) -> (np.array, np.array):
    """

    :param notes:
    :param sequence_length:
    :param data_multiplier:
    :param verbose:
    :return:
    """
    X = []
    y = []

    # create input sequences and the corresponding outputs
    multiplier = 1
    if data_multiplier is not None:
        multiplier = sequence_length//data_multiplier
    for i in tqdm(range(0, int(len(notes) - sequence_length), int(multiplier)), desc='Segmenting songs into sequences', disable=(not verbose)):
        sequence_in = notes[i:i + sequence_length]
        sequence_out = notes[i + sequence_length]
        X.append(sequence_in)
        y.append(sequence_out[:-1])

    return np.array(X), np.array(y)


def create_model_notes(X_shape) -> Sequential:
    lstm_model = Sequential()
    lstm_model.add(LSTM(
        256,
        input_shape=X_shape,
        return_sequences=True, activation='tanh'
    ))
    lstm_model.add(Dropout(0.2))
    lstm_model.add(LSTM(512, return_sequences=True, activation='tanh'))
    lstm_model.add(Dropout(0.2))
    lstm_model.add(LSTM(256, activation='tanh'))
    lstm_model.add(Dense(256))
    lstm_model.add(Dropout(0.2))
    lstm_model.add(Dense(256))
    lstm_model.add(Dropout(0.3))
    lstm_model.add(Dense(128))
    lstm_model.add(Activation('tanh'))
    lstm_model.compile(loss='mean_squared_error', optimizer='adam', metrics=[r2_keras])
    return lstm_model


def train_model_notes(lstm_model: Sequential, X: np.ndarray, sequence_length, X_val=None, epochs=200, initial_epoch=0,
                      validation_size=0.2, songs_per_epoch=10):
    # Split data into train and test data
    if X_val is None:
        X, X_val = train_test_split(X, test_size=validation_size, random_state=1)

    X_val_seq, y_val = sequence_songs(X_val, sequence_length, sequence_length//3)

    # Set up callbacks
    # Set when to checkpoint
    filepath = "note-model-{epoch:02d}-{loss:.4f}.hdf5"
    checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=0, save_best_only=True, mode='min')

    # Set up live training plotting
    plot = PlotLearning('r2_keras', 'r squared', 'notes_logs.txt')
    callbacks_list = [checkpoint]

    # set up training plotting
    plot.on_train_begin()
    if glob.glob('notes_logs.txt') and initial_epoch != 0:
        plot.load_in_data('notes_logs.txt')

    # train the model
    keep_data = 3
    try:
        for i in range(initial_epoch, epochs,keep_data):
            song_index = i % (len(X)-songs_per_epoch)  # choose training song
            X_seq, y = sequence_songs_size(X, song_index, 13000, sequence_length)
            for j in range(keep_data):
                train_history = lstm_model.fit(X_seq, y, validation_data=(X_val_seq, y_val),
                                               epochs=i+j+1, initial_epoch=i+j, batch_size=64,
                                               callbacks=callbacks_list, validation_freq=1, verbose=1)
                plot.on_epoch_end(train_history.epoch, train_history.history)
            plot.on_train_end()
    except:
        plot.on_train_end()
        raise

"""
def generate_music(l_model, starter_notes=30, save_file='test_output'):
    notes = load_notes()
    start = np.random.randint(0, len(X) - (starter_notes+1))
    int_to_note = dict((number, note) for number, note in enumerate(sorted(set(item for item in notes))))
    pattern = list(X[start])
    prediction_output = []
    # Run on some starter data
    for i in tqdm(range(30), desc='Seeding music generation'):
        prediction_input = np.reshape(pattern, (1, len(pattern), 1))
        prediction_input = prediction_input / float(n_vocab[0])
        prediction = l_model.predict(prediction_input, verbose=0)
        pattern = list(X[start+i])

    # generate 500 notes
    pattern = list(X[start])
    for note_index in tqdm(range(500), desc='Generating music'):
        prediction_input = np.reshape(pattern, (1, len(pattern), 1))
        prediction_input = prediction_input / float(n_vocab[0])
        prediction = l_model.predict(prediction_input, verbose=0)
        index = np.argmax(prediction)
        result = int_to_note[index]
        prediction_output.append(result)
        pattern.append(index)
        pattern = pattern[1:len(pattern)]

    offset = 0
    output_notes = []
    # create note and chord objects based on the values generated by the model
    for pattern in prediction_output:
        # pattern is a chord
        if ('.' in pattern) or pattern.isdigit():
            notes_in_chord = pattern.split('.')
            notes = []
            for current_note in notes_in_chord:
                new_note = note.Note(int(current_note))
                new_note.storedInstrument = instrument.Piano()
                notes.append(new_note)
            new_chord = chord.Chord(notes)
            new_chord.offset = offset
            output_notes.append(new_chord)
        # pattern is a note
        else:
            new_note = note.Note(pattern)
            new_note.offset = offset
            new_note.storedInstrument = instrument.Piano()
            output_notes.append(new_note)
        # increase offset each iteration so that notes do not stack
        offset += 0.5

    midi_stream = stream.Stream(output_notes)
    midi_stream.write('midi', fp=save_file+'.mid')
"""

if __name__ == '__main__':
    h = hpy() # can call print(h.heap()) to view current heap usage

    option = get_user_options('What would you like to do',['Train the model', 'Exit'])
    while option < 2:
        if option == 1:
            # Load in the data
            num_train = get_user_non_negative_number_or_default('How many training files do you want to load', default_message='to load all files')
            X_train = load_notes('midi_songs/training', num_train)
            X_val = load_notes('midi_songs/validation')

            sequence_length = 70
            # create model
            model = create_model_notes((sequence_length, X_train[0].shape[1]))

            if get_user_yes_no('Would you like to resume a training session'):
                start_epoch = int(get_user_non_negative_number('What epoch were you on'))
                end_epoch = int(get_user_non_negative_number('How many epochs would you like to train in total'))
                filename = get_user_filename("What is the model weight file")
                model.load_weights(filename)
                # train the model
                train_model_notes(model, X_train, sequence_length, X_val=X_val, epochs=end_epoch, songs_per_epoch=7, initial_epoch=start_epoch)
            else:
                end_epoch = int(get_user_non_negative_number('How many epochs would you like to run'))
                train_model_notes(model, X_train, sequence_length, X_val=X_val, epochs=end_epoch, songs_per_epoch=7)

        option = get_user_options('What would you like to do:',
                                  ['Train the model', 'Exit'])
